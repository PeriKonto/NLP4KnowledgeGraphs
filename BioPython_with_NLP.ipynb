{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "972e06d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: biopython in c:\\programdata\\anaconda3\\lib\\site-packages (1.83)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from biopython) (1.26.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -onttools (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ygments (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -onttools (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ygments (c:\\programdata\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "# Peri 20/4/24 simple routine to download papers for review\n",
    "\n",
    "!pip install biopython\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23879798",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import Entrez\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db1688e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query):\n",
    "    # Set the email address associated with the Entrez utility\n",
    "    Entrez.email = 'periklis.kontoroupis@tno.nl'\n",
    "    \n",
    "    # Use Entrez.esearch to search PubMed with the provided query\n",
    "    # Parameters:\n",
    "    # - db: specifies the PubMed database\n",
    "    # - sort: sorts the results by relevance\n",
    "    # - retmax: specifies the maximum number of results to return\n",
    "    # - retmode: specifies the format of the results to be returned (XML)\n",
    "    # - term: specifies the search query\n",
    "    handle = Entrez.esearch(db='pubmed',\n",
    "                            sort='relevance',\n",
    "                            retmax='10000',\n",
    "                            retmode='xml',\n",
    "                            term=query)\n",
    "    \n",
    "    # Read the search results\n",
    "    results = Entrez.read(handle)\n",
    "    \n",
    "    # Return the results\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8eb51384",
   "metadata": {},
   "outputs": [],
   "source": [
    "#studies = search('perovskite solar cells')\n",
    "#studiesIdList = studies['IdList']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e29af53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No studies found for keyword: AI-based exposure management  in occupational health and safety\n"
     ]
    }
   ],
   "source": [
    "def fetch_details(id_list):\n",
    "    ids = ','.join(id_list)\n",
    "    Entrez.email = 'periklis.kontoroupis@tno.n'\n",
    "    handle = Entrez.efetch(db='pubmed',\n",
    "                           retmax='10000',\n",
    "                           retmode='xml',\n",
    "                           id=ids)\n",
    "    results = Entrez.read(handle)\n",
    "    return results\n",
    "\n",
    "\n",
    "# Define keywords\n",
    "keywords = [\n",
    "\n",
    "    \"Artificial intelligence in occupational health and safety\",\n",
    "    \"Machine learning  in occupational health and safety\",\n",
    "    \"Natural language processing  in occupational health and safety\",\n",
    "    \"Deep learning  in occupational health and safety\",\n",
    "    \"AI applications  in occupational health and safety for hazard management\",\n",
    "    \" occupational health and safety risk assessment using AI\",\n",
    "    \"AI for safety management  in occupational health and safety\",\n",
    "    \"AI-based exposure management  in occupational health and safety\"\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "# Iterate over keywords\n",
    "for keyword in keywords:\n",
    "    # Search for studies\n",
    "    studies = search(keyword)\n",
    "    studiesIdList = studies['IdList']\n",
    "\n",
    "    # Check if IdList is empty\n",
    "    if not studiesIdList:\n",
    "        print(f\"No studies found for keyword: {keyword}\")\n",
    "        continue\n",
    "\n",
    "    # Fetch details for the list of studies\n",
    "    studies = fetch_details(studiesIdList)\n",
    "\n",
    "    # Rest of the code remains the same...\n",
    "\n",
    "    # Initialize empty lists to store data\n",
    "    title_list = []\n",
    "    abstract_list = []\n",
    "    journal_list = []\n",
    "    language_list = []\n",
    "    pubdate_year_list = []\n",
    "    pubdate_month_list = []\n",
    "\n",
    "    # Define chunk size for processing studies in batches\n",
    "    chunk_size = 10000\n",
    "\n",
    "    # Iterate over chunks of studiesIdList\n",
    "    for chunk_i in range(0, len(studiesIdList), chunk_size):\n",
    "        chunk = studiesIdList[chunk_i:chunk_i + chunk_size]\n",
    "        papers = fetch_details(chunk)\n",
    "        \n",
    "        # Iterate over each paper in the chunk\n",
    "        for i, paper in enumerate(papers['PubmedArticle']):\n",
    "            # Extract and append title to title_list\n",
    "            title_list.append(paper['MedlineCitation']['Article']['ArticleTitle'])\n",
    "            \n",
    "            # Try to extract abstract; if not available, append 'No Abstract'\n",
    "            try:\n",
    "                abstract = paper['MedlineCitation']['Article']['Abstract']['AbstractText'][0]\n",
    "                processed_abstract = process_abstract(abstract)\n",
    "                abstract_list.append(processed_abstract)\n",
    "            except:\n",
    "                abstract_list.append('No Abstract')\n",
    "            \n",
    "            # Extract and append journal title to journal_list\n",
    "            journal_list.append(paper['MedlineCitation']['Article']['Journal']['Title'])\n",
    "            \n",
    "            # Extract and append language to language_list\n",
    "            language_list.append(paper['MedlineCitation']['Article']['Language'][0])\n",
    "            \n",
    "            # Try to extract publication year; if not available, append 'No Data'\n",
    "            try:\n",
    "                pubdate_year_list.append(paper['MedlineCitation']['Article']['Journal']['JournalIssue']['PubDate']['Year'])\n",
    "            except:\n",
    "                pubdate_year_list.append('No Data')\n",
    "            \n",
    "            # Try to extract publication month; if not available, append 'No Data'\n",
    "            try:\n",
    "                pubdate_month_list.append(paper['MedlineCitation']['Article']['Journal']['JournalIssue']['PubDate']['Month'])\n",
    "            except:\n",
    "                pubdate_month_list.append('No Data')\n",
    "\n",
    "    # Create a DataFrame using the collected lists of data\n",
    "    df = pd.DataFrame(list(zip(\n",
    "        title_list, abstract_list, journal_list, language_list, pubdate_year_list, pubdate_month_list\n",
    "    )), \n",
    "    columns=[\n",
    "        'Title', 'Abstract', 'Journal', 'Language', 'Year','Month'\n",
    "    ])\n",
    "\n",
    "    # Save DataFrame to CSV file\n",
    "    filename = f\"{keyword.replace(' ', '_')}_papers.csv\"\n",
    "    df.to_csv(filename, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5fc259a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize empty lists to store data\n",
    "title_list = []\n",
    "abstract_list = []\n",
    "journal_list = []\n",
    "language_list = []\n",
    "pubdate_year_list = []\n",
    "pubdate_month_list = []\n",
    "\n",
    "# Fetch details for the list of studies using a function called fetch_details\n",
    "studies = fetch_details(studiesIdList)\n",
    "\n",
    "# Define chunk size for processing studies in batches\n",
    "chunk_size = 10000\n",
    "\n",
    "# Iterate over chunks of studiesIdList\n",
    "for chunk_i in range(0, len(studiesIdList), chunk_size):\n",
    "    # Get a chunk of studies\n",
    "    chunk = studiesIdList[chunk_i:chunk_i + chunk_size]\n",
    "    # Fetch details for the current chunk\n",
    "    papers = fetch_details(chunk)\n",
    "    \n",
    "    # Iterate over each paper in the chunk\n",
    "    for i, paper in enumerate(papers['PubmedArticle']):\n",
    "        # Extract and append title to title_list\n",
    "        title_list.append(paper['MedlineCitation']['Article']['ArticleTitle'])\n",
    "        \n",
    "        # Try to extract abstract; if not available, append 'No Abstract'\n",
    "        try:\n",
    "            abstract_list.append(paper['MedlineCitation']['Article']['Abstract']['AbstractText'][0])\n",
    "        except:\n",
    "            abstract_list.append('No Abstract')\n",
    "        \n",
    "        # Extract and append journal title to journal_list\n",
    "        journal_list.append(paper['MedlineCitation']['Article']['Journal']['Title'])\n",
    "        \n",
    "        # Extract and append language to language_list\n",
    "        language_list.append(paper['MedlineCitation']['Article']['Language'][0])\n",
    "        \n",
    "        # Try to extract publication year; if not available, append 'No Data'\n",
    "        try:\n",
    "            pubdate_year_list.append(paper['MedlineCitation']['Article']['Journal']['JournalIssue']['PubDate']['Year'])\n",
    "        except:\n",
    "            pubdate_year_list.append('No Data')\n",
    "        \n",
    "        # Try to extract publication month; if not available, append 'No Data'\n",
    "        try:\n",
    "            pubdate_month_list.append(paper['MedlineCitation']['Article']['Journal']['JournalIssue']['PubDate']['Month'])\n",
    "        except:\n",
    "            pubdate_month_list.append('No Data')\n",
    "\n",
    "# Create a DataFrame using the collected lists of data\n",
    "df = pd.DataFrame(list(zip(\n",
    "    title_list, abstract_list, journal_list, language_list, pubdate_year_list, pubdate_month_list\n",
    ")), \n",
    "columns=[\n",
    "    'Title', 'Abstract', 'Journal', 'Language', 'Year','Month'\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a1b9a5e",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 41\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m keyword \u001b[38;5;129;01min\u001b[39;00m keywords:\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m# Search for studies\u001b[39;00m\n\u001b[0;32m     40\u001b[0m     studies \u001b[38;5;241m=\u001b[39m search(keyword)\n\u001b[1;32m---> 41\u001b[0m     studiesIdList \u001b[38;5;241m=\u001b[39m \u001b[43mstudies\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mIdList\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;66;03m# Check if IdList is empty\u001b[39;00m\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m studiesIdList:\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from Bio import Entrez\n",
    "\n",
    "# Function to fetch details of papers given their IDs\n",
    "def fetch_details(id_list):\n",
    "    ids = ','.join(id_list)\n",
    "    Entrez.email = 'periklis.kontoroupis@tno.nl'\n",
    "    handle = Entrez.efetch(db='pubmed',\n",
    "                           retmax='10000',\n",
    "                           retmode='xml',\n",
    "                           id=ids)\n",
    "    results = Entrez.read(handle)\n",
    "    return results\n",
    "\n",
    "# Function to search for studies based on keywords\n",
    "def search(keyword):\n",
    "    # This function is not provided, assuming it exists and returns relevant data\n",
    "    pass\n",
    "\n",
    "# Function to process abstracts\n",
    "def process_abstract(abstract):\n",
    "    # This function is not provided, assuming it processes the abstract text\n",
    "    pass\n",
    "\n",
    "# Define keywords\n",
    "keywords = [\n",
    "    \"Artificial intelligence in occupational health and safety\",\n",
    "    \"Machine learning  in occupational health and safety\",\n",
    "    \"Natural language processing  in occupational health and safety\",\n",
    "    \"Deep learning  in occupational health and safety\",\n",
    "    \"AI applications  in occupational health and safety for hazard management\",\n",
    "    \" occupational health and safety risk assessment using AI\",\n",
    "    \"AI for safety management  in occupational health and safety\",\n",
    "    \"AI-based exposure management  in occupational health and safety\"\n",
    "]\n",
    "\n",
    "# Iterate over keywords\n",
    "for keyword in keywords:\n",
    "    # Search for studies\n",
    "    studies = search(keyword)\n",
    "    studiesIdList = studies['IdList']\n",
    "\n",
    "    # Check if IdList is empty\n",
    "    if not studiesIdList:\n",
    "        print(f\"No studies found for keyword: {keyword}\")\n",
    "        continue\n",
    "\n",
    "    # Fetch details for the list of studies\n",
    "    studies = fetch_details(studiesIdList)\n",
    "\n",
    "    # Initialize empty lists to store data\n",
    "    title_list = []\n",
    "    abstract_list = []\n",
    "    journal_list = []\n",
    "    language_list = []\n",
    "    pubdate_year_list = []\n",
    "    pubdate_month_list = []\n",
    "    reference_to_oil_industry_list = []\n",
    "\n",
    "    # Define chunk size for processing studies in batches\n",
    "    chunk_size = 10000\n",
    "\n",
    "    # Iterate over chunks of studiesIdList\n",
    "    for chunk_i in range(0, len(studiesIdList), chunk_size):\n",
    "        chunk = studiesIdList[chunk_i:chunk_i + chunk_size]\n",
    "        papers = fetch_details(chunk)\n",
    "        \n",
    "        # Iterate over each paper in the chunk\n",
    "        for i, paper in enumerate(papers['PubmedArticle']):\n",
    "            # Extract and append title to title_list\n",
    "            title_list.append(paper['MedlineCitation']['Article']['ArticleTitle'])\n",
    "            \n",
    "            # Try to extract abstract; if not available, append 'No Abstract'\n",
    "            try:\n",
    "                abstract = paper['MedlineCitation']['Article']['Abstract']['AbstractText'][0]\n",
    "                processed_abstract = process_abstract(abstract)\n",
    "                abstract_list.append(processed_abstract)\n",
    "                \n",
    "                # Check if the abstract contains a reference to the oil industry\n",
    "                if 'oil industry' in abstract.lower():\n",
    "                    reference_to_oil_industry = True\n",
    "                else:\n",
    "                    reference_to_oil_industry = False\n",
    "            except:\n",
    "                abstract_list.append('No Abstract')\n",
    "                reference_to_oil_industry = False\n",
    "            \n",
    "            # Extract and append journal title to journal_list\n",
    "            journal_list.append(paper['MedlineCitation']['Article']['Journal']['Title'])\n",
    "            \n",
    "            # Extract and append language to language_list\n",
    "            language_list.append(paper['MedlineCitation']['Article']['Language'][0])\n",
    "            \n",
    "            # Try to extract publication year; if not available, append 'No Data'\n",
    "            try:\n",
    "                pubdate_year_list.append(paper['MedlineCitation']['Article']['Journal']['JournalIssue']['PubDate']['Year'])\n",
    "            except:\n",
    "                pubdate_year_list.append('No Data')\n",
    "            \n",
    "            # Try to extract publication month; if not available, append 'No Data'\n",
    "            try:\n",
    "                pubdate_month_list.append(paper['MedlineCitation']['Article']['Journal']['JournalIssue']['PubDate']['Month'])\n",
    "            except:\n",
    "                pubdate_month_list.append('No Data')\n",
    "            \n",
    "            # Append whether there's a reference to the oil industry\n",
    "            reference_to_oil_industry_list.append(reference_to_oil_industry)\n",
    "\n",
    "    # Create a DataFrame using the collected lists of data\n",
    "    df = pd.DataFrame(list(zip(\n",
    "        title_list, abstract_list, journal_list, language_list, pubdate_year_list, pubdate_month_list, reference_to_oil_industry_list\n",
    "    )), \n",
    "    columns=[\n",
    "        'Title', 'Abstract', 'Journal', 'Language', 'Year','Month', 'Reference to Oil Industry'\n",
    "    ])\n",
    "\n",
    "    # Save DataFrame to CSV file\n",
    "    filename = f\"{keyword.replace(' ', '_')}_papers.csv\"\n",
    "    df.to_csv(filename, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd95f9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
